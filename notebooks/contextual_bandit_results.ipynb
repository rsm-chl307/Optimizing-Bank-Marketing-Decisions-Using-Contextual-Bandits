{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf91a77d",
   "metadata": {},
   "source": [
    "# Contextual Bandit: Offline Thompson Sampling\n",
    "\n",
    "In the previous notebook, we established random and greedy baselines using replay-based offline evaluation.\n",
    "These baselines provide reference points for decision quality under a fully offline setting.\n",
    "\n",
    "In this notebook, we introduce an **offline contextual bandit approach using Thompson Sampling**.\n",
    "Rather than simulating online exploration, we learn from historical data in a batch manner and evaluate decision quality under uncertainty using a conservative replay-based framework.\n",
    "\n",
    "The objective is to assess whether an uncertainty-aware, learning-based policy can outperform fixed baselines when restricted to observable historical outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "117e54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Callable, Dict\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32b65339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (45211, 18)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "row_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "marital",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "education",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "default",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "housing",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loan",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contact",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "balance_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "campaign",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "campaign_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pdays_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "previous_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "poutcome",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reward",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c1e53315-e450-4934-91be-0a9020507b56",
       "rows": [
        [
         "0",
         "0",
         "pre_retirement",
         "management",
         "married",
         "tertiary",
         "no",
         "yes",
         "no",
         "unknown",
         "may",
         "high_balance",
         "1",
         "day_1_7",
         "1_10_contacts",
         "never_contacted",
         "0_10_previous",
         "unknown",
         "0"
        ],
        [
         "1",
         "1",
         "mid_career",
         "technician",
         "single",
         "secondary",
         "no",
         "yes",
         "no",
         "unknown",
         "may",
         "low_balance",
         "1",
         "day_1_7",
         "1_10_contacts",
         "never_contacted",
         "0_10_previous",
         "unknown",
         "0"
        ],
        [
         "2",
         "2",
         "young_adult",
         "entrepreneur",
         "married",
         "secondary",
         "no",
         "yes",
         "yes",
         "unknown",
         "may",
         "low_balance",
         "1",
         "day_1_7",
         "1_10_contacts",
         "never_contacted",
         "0_10_previous",
         "unknown",
         "0"
        ],
        [
         "3",
         "3",
         "mid_career",
         "blue-collar",
         "married",
         "unknown",
         "no",
         "yes",
         "no",
         "unknown",
         "may",
         "high_balance",
         "1",
         "day_1_7",
         "1_10_contacts",
         "never_contacted",
         "0_10_previous",
         "unknown",
         "0"
        ],
        [
         "4",
         "4",
         "young_adult",
         "unknown",
         "single",
         "unknown",
         "no",
         "no",
         "no",
         "unknown",
         "may",
         "low_balance",
         "1",
         "day_1_7",
         "1_10_contacts",
         "never_contacted",
         "0_10_previous",
         "unknown",
         "0"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>age_group</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>balance_group</th>\n",
       "      <th>campaign</th>\n",
       "      <th>day_group</th>\n",
       "      <th>campaign_group</th>\n",
       "      <th>pdays_group</th>\n",
       "      <th>previous_group</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pre_retirement</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>high_balance</td>\n",
       "      <td>1</td>\n",
       "      <td>day_1_7</td>\n",
       "      <td>1_10_contacts</td>\n",
       "      <td>never_contacted</td>\n",
       "      <td>0_10_previous</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mid_career</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>low_balance</td>\n",
       "      <td>1</td>\n",
       "      <td>day_1_7</td>\n",
       "      <td>1_10_contacts</td>\n",
       "      <td>never_contacted</td>\n",
       "      <td>0_10_previous</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>young_adult</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>low_balance</td>\n",
       "      <td>1</td>\n",
       "      <td>day_1_7</td>\n",
       "      <td>1_10_contacts</td>\n",
       "      <td>never_contacted</td>\n",
       "      <td>0_10_previous</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mid_career</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>high_balance</td>\n",
       "      <td>1</td>\n",
       "      <td>day_1_7</td>\n",
       "      <td>1_10_contacts</td>\n",
       "      <td>never_contacted</td>\n",
       "      <td>0_10_previous</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>young_adult</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>may</td>\n",
       "      <td>low_balance</td>\n",
       "      <td>1</td>\n",
       "      <td>day_1_7</td>\n",
       "      <td>1_10_contacts</td>\n",
       "      <td>never_contacted</td>\n",
       "      <td>0_10_previous</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id       age_group           job  marital  education default housing  \\\n",
       "0       0  pre_retirement    management  married   tertiary      no     yes   \n",
       "1       1      mid_career    technician   single  secondary      no     yes   \n",
       "2       2     young_adult  entrepreneur  married  secondary      no     yes   \n",
       "3       3      mid_career   blue-collar  married    unknown      no     yes   \n",
       "4       4     young_adult       unknown   single    unknown      no      no   \n",
       "\n",
       "  loan  contact month balance_group  campaign day_group campaign_group  \\\n",
       "0   no  unknown   may  high_balance         1   day_1_7  1_10_contacts   \n",
       "1   no  unknown   may   low_balance         1   day_1_7  1_10_contacts   \n",
       "2  yes  unknown   may   low_balance         1   day_1_7  1_10_contacts   \n",
       "3   no  unknown   may  high_balance         1   day_1_7  1_10_contacts   \n",
       "4   no  unknown   may   low_balance         1   day_1_7  1_10_contacts   \n",
       "\n",
       "       pdays_group previous_group poutcome  reward  \n",
       "0  never_contacted  0_10_previous  unknown       0  \n",
       "1  never_contacted  0_10_previous  unknown       0  \n",
       "2  never_contacted  0_10_previous  unknown       0  \n",
       "3  never_contacted  0_10_previous  unknown       0  \n",
       "4  never_contacted  0_10_previous  unknown       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path configuration\n",
    "DATA_DIR = \"../data\"\n",
    "PROCESSED_PATH = os.path.join(DATA_DIR, \"bank_processed_for_bandit.csv\")\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_csv(PROCESSED_PATH)\n",
    "\n",
    "# Basic checks\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe6b15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined action space:\n",
      "1: low_intensity_contact\n",
      "2: high_intensity_contact\n"
     ]
    }
   ],
   "source": [
    "# Action space definition\n",
    "ACTION_LOW_INTENSITY = 1\n",
    "ACTION_HIGH_INTENSITY = 2\n",
    "\n",
    "ACTION_SPACE = [\n",
    "    ACTION_LOW_INTENSITY,\n",
    "    ACTION_HIGH_INTENSITY\n",
    "]\n",
    "\n",
    "ACTION_NAMES = {\n",
    "    ACTION_LOW_INTENSITY: \"low_intensity_contact\",\n",
    "    ACTION_HIGH_INTENSITY: \"high_intensity_contact\"\n",
    "}\n",
    "\n",
    "print(\"Defined action space:\")\n",
    "for a in ACTION_SPACE:\n",
    "    print(f\"{a}: {ACTION_NAMES[a]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dc7f21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "historical_action",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "555ab000-f239-41d4-a9fe-537d742093d6",
       "rows": [
        [
         "2",
         "0.6119528433345867"
        ],
        [
         "1",
         "0.3880471566654133"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "historical_action\n",
       "2    0.611953\n",
       "1    0.388047\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer_historical_action_from_campaign(campaign: int) -> int:\n",
    "    \"\"\"\n",
    "    Map historical campaign counts to contact intensity actions.\n",
    "    \n",
    "    - 1 contact   -> low intensity\n",
    "    - 2+ contacts -> high intensity\n",
    "    \n",
    "    No-contact is rarely observed in the historical data.\n",
    "    \"\"\"\n",
    "    if campaign == 1:\n",
    "        return ACTION_LOW_INTENSITY\n",
    "    else:\n",
    "        return ACTION_HIGH_INTENSITY\n",
    "\n",
    "df['historical_action'] = df['campaign'].apply(infer_historical_action_from_campaign)\n",
    "df['historical_action'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29044fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay_evaluate(\n",
    "    df,\n",
    "    policy_fn: Callable,\n",
    "    reward_col: str = \"reward\",\n",
    "    historical_action_col: str = \"historical_action\"\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Replay-based offline evaluation.\n",
    "\n",
    "    For each row:\n",
    "    - policy selects an action based on the state\n",
    "    - reward is counted only if policy_action == historical_action\n",
    "    \"\"\"\n",
    "\n",
    "    total_reward = 0\n",
    "    matched_steps = 0\n",
    "    n_rows = len(df)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        policy_action = policy_fn(row)\n",
    "        historical_action = row[historical_action_col]\n",
    "\n",
    "        if policy_action == historical_action:\n",
    "            total_reward += row[reward_col]\n",
    "            matched_steps += 1\n",
    "\n",
    "    match_rate = matched_steps / n_rows if n_rows > 0 else 0.0\n",
    "    avg_reward_on_matched = (\n",
    "        total_reward / matched_steps if matched_steps > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"n_rows\": n_rows,\n",
    "        \"matched_steps\": matched_steps,\n",
    "        \"match_rate\": match_rate,\n",
    "        \"total_reward_on_matched\": total_reward,\n",
    "        \"avg_reward_on_matched\": avg_reward_on_matched\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "786940e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_rows': 45211,\n",
       " 'matched_steps': 22489,\n",
       " 'match_rate': 0.49742319347061553,\n",
       " 'total_reward_on_matched': 2624,\n",
       " 'avg_reward_on_matched': 0.11667926541864912}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = random.Random(42)\n",
    "\n",
    "def random_policy(_row):\n",
    "    return rng.choice(ACTION_SPACE)\n",
    "\n",
    "\n",
    "metrics_random = replay_evaluate(df, random_policy)\n",
    "metrics_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c800536",
   "metadata": {},
   "source": [
    "## RL Model\n",
    "\n",
    "### Policy: Offline Linear Thompson Sampling\n",
    "\n",
    "We use **Offline Linear Thompson Sampling** to model the decision policy.\n",
    "\n",
    "- For each action, the expected reward is modeled as a linear function of contextual features.\n",
    "- A Bayesian posterior over the linear coefficients is estimated using historical data.\n",
    "- At decision time, parameters are sampled from the posterior to account for uncertainty, and actions are selected accordingly.\n",
    "\n",
    "Policy evaluation is conducted using replay-based action matching, ensuring that rewards are only observed when the selected action aligns with historical behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed0316ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_COLS = [\n",
    "    \"age_group\",\n",
    "    \"job\",\n",
    "    \"education\",\n",
    "    \"balance_group\",\n",
    "    \"pdays_group\",\n",
    "    \"previous_group\",\n",
    "    \"poutcome\",\n",
    "    \"month\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cd1acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 52)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATE_COLS = [c for c in STATE_COLS if c in df.columns]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), STATE_COLS)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X = preprocess.fit_transform(df[STATE_COLS])\n",
    "r = df[\"reward\"].to_numpy().astype(float)\n",
    "a_hist = df[\"historical_action\"].to_numpy().astype(int)\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7ad5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_offline_linear_ts(X, r, a_hist, actions, lam=1.0):\n",
    "    d = X.shape[1]\n",
    "    A = {a: lam * np.eye(d) for a in actions}\n",
    "    b = {a: np.zeros(d) for a in actions}\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        a = a_hist[i]\n",
    "        x = X[i]\n",
    "        reward = r[i]\n",
    "\n",
    "        A[a] += np.outer(x, x)\n",
    "        b[a] += x * reward\n",
    "\n",
    "    return A, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb0fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OfflineLinearThompsonSampling:\n",
    "    def __init__(self, A, b, v=1.0, seed=42):\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "        self.v = float(v)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        self.L = {}\n",
    "        self.mu = {}\n",
    "\n",
    "        for a in A:\n",
    "            # A = L L^T\n",
    "            L = np.linalg.cholesky(A[a])\n",
    "            self.L[a] = L\n",
    "\n",
    "            # Solve A mu = b via Cholesky: L y = b, then L^T mu = y\n",
    "            y = np.linalg.solve(L, b[a])\n",
    "            mu = np.linalg.solve(L.T, y)\n",
    "            self.mu[a] = mu\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        scores = {}\n",
    "        d = x.shape[0]\n",
    "\n",
    "        for a in self.A:\n",
    "            z = self.rng.standard_normal(d)\n",
    "            y = np.linalg.solve(self.L[a], z)     # ~ N(0, A^{-1})\n",
    "            theta = self.mu[a] + self.v * y\n",
    "            scores[a] = float(x @ theta)\n",
    "\n",
    "        return max(scores, key=scores.get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23a71c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_ts_replay_evaluate(X, r, a_hist, policy):\n",
    "    matched = 0\n",
    "    total_reward = 0.0\n",
    "    n = len(X)\n",
    "\n",
    "    for i in range(n):\n",
    "        a_hat = policy.choose_action(X[i])\n",
    "        if a_hat == a_hist[i]:\n",
    "            matched += 1\n",
    "            total_reward += r[i]\n",
    "\n",
    "    return {\n",
    "        \"n_rows\": n,\n",
    "        \"matched_steps\": matched,\n",
    "        \"match_rate\": matched / n,\n",
    "        \"total_reward_on_matched\": total_reward,\n",
    "        \"avg_reward_on_matched\": total_reward / matched if matched > 0 else 0.0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "593c2f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_rows': 45211,\n",
       " 'matched_steps': 22352,\n",
       " 'match_rate': 0.4943929574661034,\n",
       " 'total_reward_on_matched': 2645.0,\n",
       " 'avg_reward_on_matched': 0.11833392984967789}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTION_SPACE = [1, 2]\n",
    "\n",
    "A, b = fit_offline_linear_ts(X, r, a_hist, ACTION_SPACE, lam=1.0)\n",
    "offline_ts = OfflineLinearThompsonSampling(A, b, v=1.0, seed=42)\n",
    "\n",
    "metrics_offline_ts = offline_ts_replay_evaluate(X, r, a_hist, offline_ts)\n",
    "metrics_offline_ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1bd21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we evaluated random, greedy, and offline Thompson Sampling policies using a replay-based offline framework.\n",
    "While heuristic and learning-based policies show modest improvements over random selection on matched observations, overall gains are constrained by the structure of the historical data.\n",
    "\n",
    "Because actions in the dataset were assigned non-randomly, outcome differences reflect both policy behavior and underlying population differences. This historical selection bias limits the effectiveness of offline reinforcement learning and explains why increased model complexity does not necessarily yield better performance.\n",
    "\n",
    "These results underscore the importance of aligning reinforcement learning methods with the data generation process and motivate future work involving online experimentation, simulation-based evaluation, or causal inference techniques.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
